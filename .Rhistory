message = FALSE,
warning = FALSE
)
# Chunk 2: load-files
# Load all Datasets
library(ggplot2)
library(tidyverse)
library(janitor)
library(readxl)
library(sf)
library(dplyr)
library(knitr)
county_census <- read_csv("final_project_data/county_census_info.csv") |>
clean_names() |> rename( state = state_name, county = county_name,
state_fips = state_fips_code, county_fips = county_fips_code)
#glimpse(county_census)
merged_counties<-read_csv("final_project_data/merged_counties_since_1950.csv")|>
clean_names() |> rename(state = state_name,county = county_name)
#glimpse(merged_counties)
new_counties <- read_csv("final_project_data/new_counties_since_1950.csv") |>
clean_names() |> rename(county = new_county_name)
#glimpse(new_counties)
area_codes <- read_csv("final_project_data/cities_area_codes.csv") |>
clean_names() |> rename(state = state_or_province)
#glimpse(area_codes)
county_shapes <- st_read("final_project_data/co99_d00_shp/co99_d00.shp") |>
clean_names() |> rename(state_fips= state,county_fips = county,county = name)
#glimpse(county_shapes)
splits_path <- "final_project_data/splits_overlays.xlsx"
splits_overlays_sheets <-excel_sheets("final_project_data/splits_overlays.xlsx")
#print(splits_overlays_sheets)
# Chunk 3: process-splits
# Combine all sheets into one dataframe
splits_overlays_all <- splits_overlays_sheets |>
map_dfr( ~ read_excel(splits_path, sheet = .x) |>
clean_names() |>mutate(original_area_code = as.integer(.x)))
#glimpse(splits_overlays_all)
area_codes_original <- area_codes |> mutate(code = as.character(area_code)) |>
left_join(splits_overlays_all |>mutate(code = as.character(code)) |>
select(code, original_area_code),by = "code") |>
mutate(original_area_code = as.integer(original_area_code))
# area_codes_original |> select(city, state, area_code, original_area_code) |>
# glimpse()
# Chunk 4: spatial-join
# Match cities to counties spatially
area_codes_sf <- area_codes_original |>
filter(!is.na(latitude), !is.na(longitude)) |>
st_as_sf(coords = c("longitude", "latitude"), crs = 4326, remove = FALSE)
county_shapes <- county_shapes |> st_set_crs(4269)
county_shapes_transformed <- st_transform(county_shapes, st_crs(area_codes_sf))
cities_with_counties <- st_join(area_codes_sf,
county_shapes_transformed, left = FALSE)
# Most common original area code per county
county_area_codes <- cities_with_counties |>
st_drop_geometry() |>
group_by(state_fips, county_fips) |>
count(original_area_code, sort = TRUE) |>
slice_max(n, n = 1, with_ties = FALSE) |>
ungroup()
# Join to shapefile
county_shapes_with_area_code <- county_shapes |>
left_join(county_area_codes, by = c("state_fips", "county_fips"))
county_map_data <- county_shapes_with_area_code |>
left_join(county_census |> select(state_fips, county_fips, state),
by = c("state_fips", "county_fips"))
# Chunk 5: map-plot-function
plot_state_map <- function(state_name) {
ggplot(
data = county_map_data |> filter(state == state_name),
aes(fill = as.factor(original_area_code))) +
geom_sf(color = "white", size = 0.1) +
scale_fill_discrete(name = "Area Code") +
labs(title = paste("Original Area Codes in", state_name)) +
theme_bw() + theme(legend.position = "right")
}
# Chunk 6: plot-state-maps
plot_state_map("CALIFORNIA")
plot_state_map("NEW YORK")
plot_state_map("TEXAS")
plot_state_map("ILLINOIS")
plot_state_map("KANSAS")
plot_state_map("CONNECTICUT")
# Chunk 7: component2-summary
# Join area back into county census
county_area_km <- county_shapes |>
st_drop_geometry() |>
group_by(state_fips, county_fips) |>
summarise(area = sum(area, na.rm = TRUE))
county_census <- county_census |>
left_join(county_area_km, by = c("state_fips", "county_fips"))
# Chunk 8: build-area-summary
area_code_summary <- county_census |>
left_join(county_area_codes, by = c("state_fips", "county_fips")) |>
filter(!is.na(original_area_code)) |>
group_by(original_area_code) |>
summarise(
state_name = first(state),
area = sum(area, na.rm = TRUE),
population_1950 = sum(population_1950, na.rm = TRUE),
residence_telephones_1945 = sum(residence_telephones_1945, na.rm = TRUE),
population_under5_1950 = sum(population_under5_1950, na.rm = TRUE),
population_over65_1950 = sum(population_over65_1950, na.rm = TRUE),
births = sum(births, na.rm = TRUE),
black_prop = sum(black_pop, na.rm= TRUE)/sum(population_1950, na.rm = TRUE)
)|>mutate( original_code = original_area_code,
middle_code = substr(as.character(original_area_code), 2,2)) |> ungroup()
# Chunk 9: join-descendants
descendant_counts <- splits_overlays_all |>
count(original_area_code) |> rename(n_descendants = n)
area_code_summary <- area_code_summary |>
left_join(descendant_counts, by= c("original_code"="original_area_code")) |>
replace_na(list(n_descendants = 0))
# Chunk 10: check-area-code-summary
# Check the summary
area_code_summary |>
filter(middle_code == "1") |>
arrange(desc(population_1950)) |>
select(original_code, population_1950) |>
slice_head(n = 3)
# Chunk 11: telephones-vs-pop
ggplot(area_code_summary, aes(x = population_1950, y = residence_telephones_1945)) +
geom_point(color = "steelblue", size = 3, alpha = 0.6) +
labs(title = "Residential Telephones vs Population (1950)",
x = "Population (1950)", y = "Residential Telephones (1945)") +
theme_bw()
# Chunk 12: black-population
area_code_summary |>
slice_max(black_prop, n = 10) |>
ggplot(aes(x = reorder(as.character(original_code), black_prop), y = black_prop)) +
geom_col(fill = "darkred") + coord_flip() + labs(
title = "Top 10 Area Codes by Black Population Proportion (1950)",
x = "Original Area Code", y = "Proportion Black") + theme_bw()
# Chunk 13: births-by-middle-code
area_code_summary |>
ggplot(aes(x = as.factor(middle_code), y = births)) +
geom_boxplot(fill = "lightblue") + labs(
title = "Distribution of Births by Middle Digit of Area Code",
x = "Middle Digit", y = "Total Births (1950)") + theme_bw()
# Chunk 14: compute-dial-pulls
dial_pulls_table <- tibble(digit = 0:9, pulls = c(10, 1:9))
area_code_summary <- area_code_summary |> mutate(
digit1 = as.integer(substr(as.character(original_code), 1, 1)),
digit2 = as.integer(substr(as.character(original_code), 2, 2)),
digit3 = as.integer(substr(as.character(original_code), 3, 3))) |>
left_join(dial_pulls_table |> rename(pulls1 = pulls),
by = c("digit1" = "digit")) |>
left_join(dial_pulls_table |> rename(pulls2 = pulls),
by = c("digit2" = "digit")) |>
left_join(dial_pulls_table |> rename(pulls3 = pulls),
by = c("digit3" = "digit")) |>
mutate(dial_pulls = pulls1 + pulls2 + pulls3)
#view(area_code_summary)
# Chunk 15: verify-sum
cat("Total Population:", sum(area_code_summary$population_1950))
cat("Total Area:", sum(area_code_summary$area), "\n")
# Chunk 16: create-multi-code-flag
# Identify states with multiple original area codes
area_code_counts <- county_area_codes |>
left_join(county_census |> select(state_fips, state), by = "state_fips") |>
distinct(state, original_area_code)
multi_code_states <- area_code_counts |> count(state) |>
mutate(type = if_else(n > 1, "Multi-Code", "Single-Code"))
area_code_summary <- area_code_summary |>
left_join(multi_code_states, by = c("state_name" = "state"))
# Chunk 17: stratified-correlation
# Correlation in multi-code vs single-code states
correlation_results <- area_code_summary |> group_by(type) |>
summarise(cor = cor(population_1950, dial_pulls) , .groups = "drop")
correlation_results
# Chunk 18: scatterplot
area_code_summary |>
ggplot(aes(x = dial_pulls, y = population_1950 / 1e6, color = type)) +
geom_point(size = 3, alpha = 0.7) + geom_smooth(method = "lm", se = FALSE) +
labs( title = "Dial Pulls vs Population, by Area Code Type",
x = "Dial Pulls Required", y = "Population (Millions)",
color = "State Type") + theme_bw()
# Chunk 19: residual-analysis
residuals_df <- area_code_summary |> group_by(type) |>
group_modify(~ {model <- lm(dial_pulls ~ population_1950, data = .x)
.x |> mutate(predicted = predict(model), residual = dial_pulls - predicted)})
unfair_codes <- residuals_df |> group_by(type) |>slice_max(residual, n = 3) |>
mutate(label = "Unfairly Slow") |> bind_rows(residuals_df |> group_by(type) |>
slice_min(residual, n = 3) |> mutate(label = "Unfairly Fast"))
# Chunk 20: unfair-codes-plot
unfair_codes |>
ggplot(aes(x = reorder(as.character(original_code), residual),
y = residual, fill = label)) + geom_col(show.legend = TRUE) +
geom_text(aes(label = scales::comma(round(population_1950 / 1e6, 1))),
hjust = 0.5, size = 3) + facet_wrap(~type, scales = "free_y") +
labs(title ="Unfairly Slow vs Fast Area Codes (Based on Dial Pull Residuals)",
x = "Original Area Code", y = "Residual (Dial Pulls - Expected)") +
scale_y_continuous(expand = expansion(mult = c(0.05, 0.1)))+
scale_fill_manual(values = c("Unfairly Slow" = "firebrick",
"Unfairly Fast" = "steelblue")) + coord_flip() + theme_bw()
# Chunk 21: stratified-regression
library(tidyverse)
library(broom)
# population groups
area_code_summary <- area_code_summary |> mutate(pop_group= if_else(
population_1950 >= median(population_1950), "High Pop", "Low Pop"))
# regression fit within each group
stratified_models <- area_code_summary |> group_by(pop_group) |>
group_map(~ tidy(lm(dial_pulls ~ black_prop, data = .x)), .keep = TRUE) |>
bind_rows(.id = "group")
# Chunk 22: display-summary
stratified_models |>
select(group, term, estimate, std.error, statistic, p.value)
# Chunk 23: plot-regression
ggplot(area_code_summary, aes(x = black_prop,
y = dial_pulls, color = pop_group)) +
geom_point(alpha = 0.6) + geom_smooth(method = "lm", se = FALSE) +
labs( title = "Stratified Regression by Population Group",
x ="Proportion Black (1950)", y ="Dial Pulls", color ="Population Group") +
theme_bw()
# Chunk 24: setup-component5
library(tidyverse)
library(tidymodels)
library(janitor)
library(poissonreg)
# Prepare dataset
area_data <- area_code_summary |> select(-original_code) |>
mutate(middle_code = as.factor(middle_code)) |> drop_na()
set.seed(123)
area_split <- initial_split(area_data, prop = 0.80)
area_train <- training(area_split)
area_test  <- testing(area_split)
# Chunk 25: base-recipe
# Shared preprocessing
base_recipe <- recipe(n_descendants ~ ., data = area_train) |>
update_role(state_name, new_role = "id") |>
step_normalize(all_numeric_predictors()) |>
step_dummy(all_nominal_predictors())
# Chunk 26: linear-model
lm_spec <- linear_reg() |> set_engine("lm")
lm_wf <- workflow() |> add_recipe(base_recipe) |> add_model(lm_spec)
lm_fit <- fit(lm_wf, data = area_train)
# Predict & evaluate
lm_preds <- predict(lm_fit, area_test) |>
bind_cols(area_test |> select(n_descendants))
lm_metrics <- tibble(
model = "Linear",
rmse = rmse(lm_preds, truth = n_descendants, estimate = .pred)$.estimate,
rsq  = rsq(lm_preds,  truth = n_descendants, estimate = .pred)$.estimate
)
lm_metrics
# Chunk 27: define-models
# Specs for alternatives
ridge_spec   <- linear_reg(penalty = 1, mixture = 0) |> set_engine("glmnet")
lasso_spec   <- linear_reg(penalty = 1, mixture = 1) |> set_engine("glmnet")
knn_spec     <- nearest_neighbor(neighbors = 5) |>
set_engine("kknn") |> set_mode("regression")
tree_spec    <- decision_tree() |> set_engine("rpart") |> set_mode("regression")
boost_spec   <- boost_tree() |> set_engine("xgboost") |> set_mode("regression")
poisson_spec <- poisson_reg() |> set_engine("glm")
wf_list <- list(
Ridge    = ridge_spec,
Lasso    = lasso_spec,
KNN      = knn_spec,
Tree     = tree_spec,
Boosted  = boost_spec,
Poisson  = poisson_spec
) |> map(~ workflow() |> add_recipe(base_recipe) |> add_model(.x))
# Chunk 28: fit-models
model_results <- map_dfr(names(wf_list), function(name) {
fit_model <- fit(wf_list[[name]], area_train)
preds <- predict(fit_model, area_test) |>
bind_cols(area_test |> select(n_descendants))
tibble(
model = name,
rmse  = rmse(preds, truth = n_descendants, estimate = .pred)$.estimate,
rsq   = rsq(preds,  truth = n_descendants, estimate = .pred)$.estimate
)
})
# Chunk 29: compare-all
all_results <- bind_rows(model_results, lm_metrics) |> arrange(rmse)
kable(all_results, caption = "Model Comparison: RMSE and R²")
# Chunk 30: stepwise-model
full_lm <- lm(n_descendants ~ ., data = area_train |> select(-state_name))
step_lm <- stats::step(full_lm, direction = "both", trace = FALSE)
step_preds <- predict(step_lm, newdata = area_test)
step_metrics <- tibble(
model = "Linear_Stepwise",
rmse = rmse_vec(area_test$n_descendants, step_preds),
rsq  = rsq_vec(area_test$n_descendants, step_preds)
)
step_metrics
# Chunk 31: plot-compare-pred
compare_df <- tibble(
actual = area_test$n_descendants,
full_lm = predict(full_lm, newdata = area_test),
step_lm = step_preds
)
compare_df |>
pivot_longer(cols = c(full_lm, step_lm),
names_to = "model", values_to = "pred") |>
ggplot(aes(x = actual, y = pred, color = model)) +
geom_point(alpha = 0.6, size = 2) + geom_abline(linetype = "dashed") +
labs(title = "Predicted vs Actual for Full vs Stepwise Models",
x = "Actual Descendant Count", y = "Predicted" ) + theme_bw()
# Chunk 32: tidy-step-coefs
library(broom)
tidy(step_lm) |> select(term, estimate, std.error, p.value)
augment(step_lm, newdata = area_test) |>
ggplot(aes(.resid)) +
geom_histogram(bins = 15, fill = "steelblue") +
labs(title = "Residual Distribution (Stepwise Model)")
library(vip)
boost_fit <- fit(wf_list$Boosted, area_train)
vip::vip(extract_fit_parsnip(boost_fit), num_features = 10)
final_model <- lm(n_descendants ~ ., data = area_data |> select(-state_name))
final_preds <- predict(final_model)
library(broom)
augment(step_lm, newdata = area_test) |>
ggplot(aes(.resid)) +
geom_histogram(bins = 15, fill = "steelblue", color = "white") +
labs(
title = "Residual Distribution (Stepwise Model)",
x = "Residuals",
y = "Count"
) +
theme_minimal()
# Train on full data
final_step_lm <- lm(n_descendants ~ ., data = area_data |> select(-state_name))
# Predict for all area codes
final_predictions <- area_data |>
mutate(predicted_descendants = predict(final_step_lm, newdata = _))
library(vip)
boost_fit <- fit(wf_list$Boosted, area_train)
vip::vip(extract_fit_parsnip(boost_fit), num_features = 10)
# Train on full data
final_step_lm <- lm(n_descendants ~ ., data = area_data |> select(-state_name))
# Predict for all area codes
final_predictions <- area_data |>
mutate(predicted_descendants = predict(final_step_lm, newdata = _))
# Train on full data
final_step_lm <- lm(n_descendants ~ ., data = area_data |> select(-state_name))
# Predict for all area codes
# Predict for all area codes
final_predictions <- area_data |>
mutate(predicted_descendants = predict(final_step_lm, newdata = area_data))
# View top regions by predicted descendants
final_predictions |>
arrange(desc(predicted_descendants)) |>
select(original_code, state_name, predicted_descendants) |>
slice_head(n = 10)
final_step_lm <- lm(n_descendants ~ ., data = area_data |> select(-state_name))
# Train on full data
area_data <- area_code_summary |>
mutate(middle_code = as.factor(middle_code)) |>
drop_na()
final_step_lm <- lm(n_descendants ~ ., data = area_data |> select(-state_name))
# Predict for all area codes
# Predict for all area codes
final_predictions <- area_data |>
mutate(predicted_descendants = predict(final_step_lm, newdata = area_data))
# View top regions by predicted descendants
final_predictions |>
arrange(desc(predicted_descendants)) |>
select(original_code, state_name, predicted_descendants) |>
slice_head(n = 10)
# Train on full data
area_data <- area_code_summary |>
mutate(middle_code = as.factor(middle_code)) |>
drop_na()
final_step_lm <- lm(n_descendants ~ ., data = area_data |> select(-state_name))
# Predict for all area codes
# Predict for all area codes
final_predictions <- area_data |>
mutate(predicted_descendants = predict(final_step_lm, newdata = area_data))
# View top regions by predicted descendants
final_predictions |>
arrange(desc(predicted_descendants)) |>
select(original_code, state_name, predicted_descendants) |>
slice_head(n = 10)
ggplot(final_predictions, aes(x = n_descendants, y = predicted_descendants)) +
geom_point(color = "steelblue", alpha = 0.7, size = 3) +
geom_abline(linetype = "dashed", color = "gray") +
labs(
title = "Final Model: Actual vs Predicted Descendant Counts",
x = "Actual Descendant Count",
y = "Predicted Descendant Count"
) +
theme_minimal()
area_data <- area_code_summary |>
mutate(middle_code = as.factor(middle_code)) |>
drop_na() |> view()
AIC(step_lm)
ggplot(final_predictions, aes(x = n_descendants, y = predicted_descendants)) +
geom_point(color = "steelblue", alpha = 0.7, size = 3) +
geom_abline(linetype = "dashed", color = "gray") +
labs(
title = "Final Model: Actual vs Predicted Descendant Counts",
x = "Actual Descendant Count",
y = "Predicted Descendant Count"
) +
theme_minimal()
AIC(step_lm)
AIC(final_step_lm)
AIC(full_lm)
# Create binary classes
area_test_classified <- area_test |>
mutate(true_class = if_else(n_descendants >= 2, "High", "Low"))
# Predict classes from stepwise model
step_preds_class <- predict(step_lm, newdata = area_test) |>
as.numeric() |>
if_else(. >= 2, "High", "Low")
# Confusion matrix
conf_mat_tbl <- yardstick::conf_mat(
data = tibble(
truth = area_test_classified$true_class,
estimate = step_preds_class
),
truth = truth,
estimate = estimate
)
AIC(step_lm)
AIC(full_lm)
library(vip)
boost_fit <- fit(wf_list$Boosted, area_train)
vip::vip(extract_fit_parsnip(boost_fit), num_features = 10)
# Create binary classes
area_test_classified <- area_test |>
mutate(true_class = if_else(n_descendants >= 2, "High", "Low"))
# Predict classes from stepwise model
step_preds_class <- predict(step_lm, newdata = area_test) |>
as.numeric() |>
if_else(. >= 2, "High", "Low")
# Predict classes from stepwise model
# Predict classes from stepwise model
step_preds_class <- predict(step_lm, newdata = area_test) |>
as.numeric()
# Convert predictions to classes
step_preds_class <- if_else(step_preds_class >= 2, "High", "Low")
# Confusion matrix
conf_mat_tbl <- yardstick::conf_mat(
data = tibble(
truth = area_test_classified$true_class,
estimate = step_preds_class
),
truth = truth,
estimate = estimate
)
conf_mat_tbl
# Confusion matrix
conf_mat_tbl <- yardstick::conf_mat(
data = tibble(
truth = area_test_classified$true_class,
estimate = step_preds_class
),
truth = truth,
estimate = estimate
)
# Confusion matrix
# Convert truth and predictions to factors
conf_mat_tbl <- yardstick::conf_mat(
data = tibble(
truth = factor(area_test_classified$true_class, levels = c("Low", "High")),
estimate = factor(step_preds_class, levels = c("Low", "High"))
),
truth = truth,
estimate = estimate
)
metrics_tbl <- yardstick::metrics(
tibble(
truth = area_test_classified$true_class,
estimate = factor(step_preds_class, levels = c("Low", "High"))
),
truth = truth,
estimate = estimate
)
conf_mat_tbl
metrics_tbl <- yardstick::metrics(
tibble(
truth = area_test_classified$true_class,
estimate = factor(step_preds_class, levels = c("Low", "High"))
),
truth = truth,
estimate = estimate
)
# Create factor tibble
eval_tbl <- tibble(
truth = factor(area_test_classified$true_class, levels = c("Low", "High")),
estimate = factor(step_preds_class, levels = c("Low", "High"))
)
library(yardstick)
# Accuracy
accuracy(eval_tbl, truth = truth, estimate = estimate)
# Sensitivity (True Positive Rate)
sens(eval_tbl, truth = truth, estimate = estimate)
# Specificity (True Negative Rate)
spec(eval_tbl, truth = truth, estimate = estimate)
full_lm <- lm(n_descendants ~ ., data = area_train |> select(-state_name))
step_lm <- stats::step(full_lm, direction = "both", trace = FALSE)
step_preds <- predict(step_lm, newdata = area_test)
step_metrics <- tibble(
model = "Linear_Stepwise",
rmse = rmse_vec(area_test$n_descendants, step_preds),
rsq  = rsq_vec(area_test$n_descendants, step_preds)
)
step_metrics
AIC(step_lm)
AIC(full_lm)
conf_mat_display <- matrix(c(3, 2, 0, 11), nrow = 2, byrow = TRUE,
dimnames = list("Actual" = c("Low", "High"),"Predicted" = c("Low", "High")))
kable(conf_mat_display, caption = "Confusion Matrix")
metric_tbl <- tibble::tibble(
Metric = c("Accuracy", "Sensitivity", "Specificity"),
Value = c(
accuracy(eval_tbl, truth = truth, estimate = estimate)[[".estimate"]],
sens(eval_tbl, truth = truth, estimate = estimate)[[".estimate"]],
spec(eval_tbl, truth = truth, estimate = estimate)[[".estimate"]]))
kable(metric_tbl, caption = "Classification Metrics")
