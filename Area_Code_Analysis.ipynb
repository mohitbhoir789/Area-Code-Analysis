{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7f7dbf7",
   "metadata": {},
   "source": [
    "# STAT 5410 Final Project: Analysis of Area Codes\n",
    "\n",
    "**Author: Mohit Bhoir**\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This project investigates the historical allocation of area codes under the 1947 North American Numbering Plan (NANP) to uncover whether the design of telecommunications infrastructure reflected systemic social and demographic biases. Using spatial joins, historical census data from the 1950s, and statistical modeling, we map original area code assignments to U.S. counties and analyze patterns based on population size, race, and geographic distribution. Our work reveals that more populous regions were often given easier-to-dial codes, and in high-density areas, codes serving predominantly Black populations were disproportionately harder to dial. We build predictive models to forecast future area code splits using mid-century demographic and infrastructural features. Our findings demonstrate how early decisions in telecommunications policy have left a measurable imprint on long-term service distribution and social equity—offering a data-driven lens on infrastructure fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d1d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup environment\n",
    "# Note: You may need to install these packages if they're not already available\n",
    "# %pip install pandas numpy matplotlib seaborn plotly geopandas scikit-learn statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981e2d1e",
   "metadata": {},
   "source": [
    "# COMPONENT 1: Assigning Area Codes to Counties\n",
    "\n",
    "In Component 1, we assembled and joined multiple datasets to map each U.S. county to its original 3-digit area code, based on 1947 assignments. This involved:\n",
    "\n",
    "- Cleaning census, area code, and shapefile data\n",
    "- Performing spatial joins to identify counties for each city\n",
    "- Assigning the most common original area code per county\n",
    "- Visualizing this assignment for selected states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a18237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all Datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "from functools import reduce\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('ggplot')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Load county census data\n",
    "county_census = pd.read_csv(\"final_project_data/county_census_info.csv\")\n",
    "county_census = county_census.rename(columns={\n",
    "    'state_name': 'state', \n",
    "    'county_name': 'county',\n",
    "    'state_fips_code': 'state_fips', \n",
    "    'county_fips_code': 'county_fips'\n",
    "})\n",
    "\n",
    "# Load merged counties data\n",
    "merged_counties = pd.read_csv(\"final_project_data/merged_counties_since_1950.csv\")\n",
    "merged_counties = merged_counties.rename(columns={\n",
    "    'state_name': 'state',\n",
    "    'county_name': 'county'\n",
    "})\n",
    "\n",
    "# Load new counties data\n",
    "new_counties = pd.read_csv(\"final_project_data/new_counties_since_1950.csv\")\n",
    "new_counties = new_counties.rename(columns={\n",
    "    'new_county_name': 'county'\n",
    "})\n",
    "\n",
    "# Load area codes data\n",
    "area_codes = pd.read_csv(\"final_project_data/cities_area_codes.csv\")\n",
    "area_codes = area_codes.rename(columns={\n",
    "    'state_or_province': 'state'\n",
    "})\n",
    "\n",
    "# Load county shapefile data\n",
    "county_shapes = gpd.read_file(\"final_project_data/co99_d00_shp/co99_d00.shp\")\n",
    "county_shapes = county_shapes.rename(columns={\n",
    "    'state': 'state_fips',\n",
    "    'county': 'county_fips',\n",
    "    'name': 'county'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3126e365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process splits and overlays data\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Get all sheets from the Excel file\n",
    "splits_path = \"final_project_data/splits_overlays.xlsx\"\n",
    "splits_overlays_sheets = pd.ExcelFile(splits_path).sheet_names\n",
    "\n",
    "# Combine all sheets into one dataframe\n",
    "splits_overlays_all = pd.DataFrame()\n",
    "for sheet in splits_overlays_sheets:\n",
    "    df = pd.read_excel(splits_path, sheet_name=sheet)\n",
    "    df = df.rename(columns=lambda x: x.lower().replace(' ', '_'))\n",
    "    df['original_area_code'] = int(sheet)\n",
    "    splits_overlays_all = pd.concat([splits_overlays_all, df])\n",
    "\n",
    "# Join original area codes with area codes data\n",
    "area_codes_original = area_codes.copy()\n",
    "area_codes_original['code'] = area_codes_original['area_code'].astype(str)\n",
    "splits_overlays_all['code'] = splits_overlays_all['code'].astype(str)\n",
    "\n",
    "area_codes_original = pd.merge(\n",
    "    area_codes_original,\n",
    "    splits_overlays_all[['code', 'original_area_code']],\n",
    "    on='code',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf7cb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial join to match cities to counties\n",
    "# Convert area codes to GeoDataFrame\n",
    "area_codes_sf = area_codes_original[\n",
    "    ~area_codes_original['latitude'].isna() & \n",
    "    ~area_codes_original['longitude'].isna()\n",
    "].copy()\n",
    "\n",
    "area_codes_sf = gpd.GeoDataFrame(\n",
    "    area_codes_sf, \n",
    "    geometry=gpd.points_from_xy(area_codes_sf.longitude, area_codes_sf.latitude),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Set CRS for county shapes\n",
    "county_shapes = county_shapes.set_crs(\"EPSG:4269\")\n",
    "\n",
    "# Transform county shapes to match area codes CRS\n",
    "county_shapes_transformed = county_shapes.to_crs(area_codes_sf.crs)\n",
    "\n",
    "# Perform spatial join\n",
    "cities_with_counties = gpd.sjoin(area_codes_sf, county_shapes_transformed, how=\"inner\")\n",
    "\n",
    "# Find most common original area code per county\n",
    "county_area_codes = cities_with_counties.drop(columns='geometry').groupby(['state_fips', 'county_fips'])\n",
    "county_area_codes = county_area_codes['original_area_code'].agg(\n",
    "    lambda x: x.value_counts().index[0] if not x.isna().all() else None\n",
    ").reset_index()\n",
    "county_area_codes.columns = ['state_fips', 'county_fips', 'original_area_code']\n",
    "\n",
    "# Join to shapefile\n",
    "county_shapes_with_area_code = county_shapes.merge(\n",
    "    county_area_codes, \n",
    "    on=['state_fips', 'county_fips'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "county_map_data = county_shapes_with_area_code.merge(\n",
    "    county_census[['state_fips', 'county_fips', 'state']],\n",
    "    on=['state_fips', 'county_fips'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc5c4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot state maps\n",
    "def plot_state_map(state_name):\n",
    "    state_data = county_map_data[county_map_data['state'] == state_name]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    state_data.plot(\n",
    "        column='original_area_code', \n",
    "        categorical=True,\n",
    "        legend=True,\n",
    "        ax=ax,\n",
    "        edgecolor='white',\n",
    "        linewidth=0.1\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f\"Original Area Codes in {state_name}\", fontsize=15)\n",
    "    ax.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Plot maps for selected states\n",
    "states_to_plot = [\"CALIFORNIA\", \"NEW YORK\", \"TEXAS\", \"ILLINOIS\", \"KANSAS\", \"CONNECTICUT\"]\n",
    "for state in states_to_plot:\n",
    "    plot_state_map(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72c4bea",
   "metadata": {},
   "source": [
    "The maps show distinct patterns of original area code assignment across states. Urbanized states such as New York and California exhibit dense clusters of area codes, especially around major cities like New York City and Los Angeles. In contrast, rural states like Kansas have larger, more uniformly distributed area code zones. These visualizations not only confirm the success of my spatial join and aggregation process, but also closely match the historical area code maps provided in the reference links within the project prompt, further validating the accuracy of the implementation.\n",
    "\n",
    "---\n",
    "\n",
    "# COMPONENT 2: Summarizing Regional Characteristics by Area Code\n",
    "\n",
    "In this component, we constructed a summary dataset for each original area code based on demographic, telephone, and geographic information from the 1940s–1950s. This data provides the foundation for later modeling and fairness analysis.\n",
    "\n",
    "Specifically, we:\n",
    "\n",
    "- Aggregated census and area variables from the county to the area code level\n",
    "- Calculated region-wide totals and ratios (e.g., birth rate, Black population proportion)\n",
    "- Joined with descendant area code counts for future modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d87f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate county area\n",
    "county_area_km = county_shapes.drop(columns='geometry').groupby(['state_fips', 'county_fips'])\n",
    "county_area_km = county_area_km['area'].sum().reset_index()\n",
    "\n",
    "# Join area to county census\n",
    "county_census = county_census.merge(\n",
    "    county_area_km, \n",
    "    on=['state_fips', 'county_fips'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c630f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build area code summary statistics\n",
    "area_code_summary = county_census.merge(\n",
    "    county_area_codes,\n",
    "    on=['state_fips', 'county_fips'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "area_code_summary = area_code_summary[~area_code_summary['original_area_code'].isna()]\n",
    "\n",
    "# Group by area code and calculate summary statistics\n",
    "area_code_summary = area_code_summary.groupby('original_area_code').agg({\n",
    "    'state': 'first',\n",
    "    'area': 'sum',\n",
    "    'population_1950': 'sum',\n",
    "    'residence_telephones_1945': 'sum',\n",
    "    'population_under5_1950': 'sum',\n",
    "    'population_over65_1950': 'sum',\n",
    "    'births': 'sum',\n",
    "    'black_pop': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Calculate Black population proportion\n",
    "area_code_summary['black_prop'] = area_code_summary['black_pop'] / area_code_summary['population_1950']\n",
    "\n",
    "# Add middle code digit (for later analysis)\n",
    "area_code_summary['original_code'] = area_code_summary['original_area_code']\n",
    "area_code_summary['middle_code'] = area_code_summary['original_area_code'].astype(str).str[1]\n",
    "\n",
    "# Join descendant counts\n",
    "descendant_counts = splits_overlays_all.groupby('original_area_code').size().reset_index()\n",
    "descendant_counts.columns = ['original_area_code', 'n_descendants']\n",
    "\n",
    "area_code_summary = area_code_summary.merge(\n",
    "    descendant_counts,\n",
    "    left_on='original_code',\n",
    "    right_on='original_area_code',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "area_code_summary['n_descendants'] = area_code_summary['n_descendants'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ba63b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the summary\n",
    "area_code_summary[area_code_summary['middle_code'] == '1'].sort_values(\n",
    "    by='population_1950', ascending=False\n",
    ")[['original_code', 'population_1950']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2ec0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot telephones vs population\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(\n",
    "    area_code_summary['population_1950'], \n",
    "    area_code_summary['residence_telephones_1945'],\n",
    "    color='steelblue', \n",
    "    alpha=0.6,\n",
    "    s=60\n",
    ")\n",
    "plt.title('Residential Telephones vs Population (1950)', fontsize=14)\n",
    "plt.xlabel('Population (1950)')\n",
    "plt.ylabel('Residential Telephones (1945)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f961e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 10 area codes by Black population proportion\n",
    "top10_black = area_code_summary.sort_values('black_prop', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(\n",
    "    top10_black['original_code'].astype(str),\n",
    "    top10_black['black_prop'],\n",
    "    color='darkred'\n",
    ")\n",
    "plt.title('Top 10 Area Codes by Black Population Proportion (1950)', fontsize=14)\n",
    "plt.xlabel('Proportion Black')\n",
    "plt.ylabel('Original Area Code')\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c69ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of births by middle digit\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='middle_code', y='births', data=area_code_summary, color='lightblue')\n",
    "plt.title('Distribution of Births by Middle Digit of Area Code', fontsize=14)\n",
    "plt.xlabel('Middle Digit')\n",
    "plt.ylabel('Total Births (1950)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46e5e58",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# COMPONENT 3: Dialing Effort and Population – Stratified Analysis\n",
    "\n",
    "This component evaluates whether more populous areas were intentionally assigned area codes that required fewer rotary dial pulls, especially within states that had multiple area codes to choose from.\n",
    "\n",
    "We split states into:\n",
    "\n",
    "- Multi-Code States (states assigned more than one area code in 1947)\n",
    "- Single-Code States (states with only one assigned code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b262ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute dial pulls for each area code\n",
    "dial_pulls_table = pd.DataFrame({\n",
    "    'digit': range(10),\n",
    "    'pulls': [10, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "})\n",
    "\n",
    "# Extract digits from area codes\n",
    "area_code_summary['digit1'] = area_code_summary['original_code'].astype(str).str[0].astype(int)\n",
    "area_code_summary['digit2'] = area_code_summary['original_code'].astype(str).str[1].astype(int)\n",
    "area_code_summary['digit3'] = area_code_summary['original_code'].astype(str).str[2].astype(int)\n",
    "\n",
    "# Join with dial pulls table\n",
    "area_code_summary = area_code_summary.merge(\n",
    "    dial_pulls_table.rename(columns={'pulls': 'pulls1'}),\n",
    "    left_on='digit1',\n",
    "    right_on='digit',\n",
    "    how='left'\n",
    ").drop(columns='digit')\n",
    "\n",
    "area_code_summary = area_code_summary.merge(\n",
    "    dial_pulls_table.rename(columns={'pulls': 'pulls2'}),\n",
    "    left_on='digit2',\n",
    "    right_on='digit',\n",
    "    how='left'\n",
    ").drop(columns='digit')\n",
    "\n",
    "area_code_summary = area_code_summary.merge(\n",
    "    dial_pulls_table.rename(columns={'pulls': 'pulls3'}),\n",
    "    left_on='digit3',\n",
    "    right_on='digit',\n",
    "    how='left'\n",
    ").drop(columns='digit')\n",
    "\n",
    "# Calculate total dial pulls\n",
    "area_code_summary['dial_pulls'] = area_code_summary['pulls1'] + area_code_summary['pulls2'] + area_code_summary['pulls3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bab501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify aggregation\n",
    "print(f\"Total Population: {area_code_summary['population_1950'].sum():,.0f}\")\n",
    "print(f\"Total Area: {area_code_summary['area'].sum():,.0f} km²\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43df90a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify states with multiple original area codes\n",
    "area_code_counts = county_area_codes.merge(\n",
    "    county_census[['state_fips', 'state']].drop_duplicates(),\n",
    "    on='state_fips',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "area_code_counts = area_code_counts[['state', 'original_area_code']].drop_duplicates()\n",
    "\n",
    "multi_code_states = area_code_counts.groupby('state').size().reset_index()\n",
    "multi_code_states.columns = ['state', 'n']\n",
    "multi_code_states['type'] = np.where(multi_code_states['n'] > 1, 'Multi-Code', 'Single-Code')\n",
    "\n",
    "# Join to area code summary\n",
    "area_code_summary = area_code_summary.merge(\n",
    "    multi_code_states,\n",
    "    left_on='state',\n",
    "    right_on='state',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4b7443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation in multi-code vs single-code states\n",
    "correlation_results = area_code_summary.groupby('type').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'cor': np.corrcoef(x['population_1950'], x['dial_pulls'])[0, 1]\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "correlation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24091772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot relationship between dial pulls and 1950 population\n",
    "plt.figure(figsize=(12, 7))\n",
    "for type_name, group in area_code_summary.groupby('type'):\n",
    "    plt.scatter(\n",
    "        group['dial_pulls'],\n",
    "        group['population_1950'] / 1e6,\n",
    "        label=type_name,\n",
    "        alpha=0.7,\n",
    "        s=70\n",
    "    )\n",
    "    \n",
    "    # Add regression line\n",
    "    x = group['dial_pulls']\n",
    "    y = group['population_1950'] / 1e6\n",
    "    z = np.polyfit(x, y, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(x, p(x), '--')\n",
    "\n",
    "plt.title('Dial Pulls vs Population, by Area Code Type', fontsize=14)\n",
    "plt.xlabel('Dial Pulls Required')\n",
    "plt.ylabel('Population (Millions)')\n",
    "plt.legend(title='State Type')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17b5f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis to find unfairly slow or fast codes\n",
    "residuals_df = pd.DataFrame()\n",
    "\n",
    "for type_name, group in area_code_summary.groupby('type'):\n",
    "    # Fit linear model\n",
    "    X = group['population_1950'].values.reshape(-1, 1)\n",
    "    y = group['dial_pulls'].values\n",
    "    \n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    model = LinearRegression().fit(X, y)\n",
    "    \n",
    "    # Get predictions and residuals\n",
    "    predicted = model.predict(X)\n",
    "    residual = y - predicted\n",
    "    \n",
    "    # Create dataframe with results\n",
    "    group_df = group.copy()\n",
    "    group_df['predicted'] = predicted\n",
    "    group_df['residual'] = residual\n",
    "    residuals_df = pd.concat([residuals_df, group_df])\n",
    "\n",
    "# Find unfairly slow codes (high positive residuals)\n",
    "unfair_slow = residuals_df.groupby('type').apply(\n",
    "    lambda x: x.nlargest(3, 'residual')\n",
    ").reset_index(drop=True)\n",
    "unfair_slow['label'] = 'Unfairly Slow'\n",
    "\n",
    "# Find unfairly fast codes (high negative residuals)\n",
    "unfair_fast = residuals_df.groupby('type').apply(\n",
    "    lambda x: x.nsmallest(3, 'residual')\n",
    ").reset_index(drop=True)\n",
    "unfair_fast['label'] = 'Unfairly Fast'\n",
    "\n",
    "# Combine unfair codes\n",
    "unfair_codes = pd.concat([unfair_slow, unfair_fast])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b05beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot unfair codes\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Create a categorical color map\n",
    "colors = {'Unfairly Slow': 'firebrick', 'Unfairly Fast': 'steelblue'}\n",
    "\n",
    "# Plot for Multi-Code\n",
    "plt.subplot(1, 2, 1)\n",
    "multi_codes = unfair_codes[unfair_codes['type'] == 'Multi-Code']\n",
    "bars = plt.barh(\n",
    "    multi_codes['original_code'].astype(str),\n",
    "    multi_codes['residual'],\n",
    "    color=multi_codes['label'].map(colors)\n",
    ")\n",
    "\n",
    "# Add population labels\n",
    "for i, v in enumerate(multi_codes['residual']):\n",
    "    plt.text(\n",
    "        v/2 if v > 0 else v/2, \n",
    "        i, \n",
    "        f\"{multi_codes['population_1950'].iloc[i]/1e6:.1f}M\",\n",
    "        ha='center',\n",
    "        va='center'\n",
    "    )\n",
    "    \n",
    "plt.title('Multi-Code States')\n",
    "plt.xlabel('Residual (Dial Pulls - Expected)')\n",
    "plt.ylabel('Original Area Code')\n",
    "\n",
    "# Plot for Single-Code\n",
    "plt.subplot(1, 2, 2)\n",
    "single_codes = unfair_codes[unfair_codes['type'] == 'Single-Code']\n",
    "bars = plt.barh(\n",
    "    single_codes['original_code'].astype(str),\n",
    "    single_codes['residual'],\n",
    "    color=single_codes['label'].map(colors)\n",
    ")\n",
    "\n",
    "# Add population labels\n",
    "for i, v in enumerate(single_codes['residual']):\n",
    "    plt.text(\n",
    "        v/2 if v > 0 else v/2, \n",
    "        i, \n",
    "        f\"{single_codes['population_1950'].iloc[i]/1e6:.1f}M\",\n",
    "        ha='center',\n",
    "        va='center'\n",
    "    )\n",
    "\n",
    "plt.title('Single-Code States')\n",
    "plt.xlabel('Residual (Dial Pulls - Expected)')\n",
    "\n",
    "plt.suptitle('Unfairly Slow vs Fast Area Codes (Based on Dial Pull Residuals)', fontsize=14)\n",
    "\n",
    "# Add a common legend\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color=colors['Unfairly Slow'], lw=4, label='Unfairly Slow'),\n",
    "    Line2D([0], [0], color=colors['Unfairly Fast'], lw=4, label='Unfairly Fast')\n",
    "]\n",
    "plt.figlegend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, 0.05), ncol=2)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.1, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a2f2a5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# COMPONENT 4: Racial Disparities in Dialing Effort\n",
    "\n",
    "In this section, we investigate whether AT&T's 1947 area code assignments were discriminatory toward regions with higher proportions of Black residents by assigning them codes that were slower to dial on rotary phones.\n",
    "\n",
    "To assess this, we stratify the data into High Pop and Low Pop groups (based on the median 1950 population) and fit separate linear regression models of dialing effort on Black population proportion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c808b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create population groups\n",
    "area_code_summary['pop_group'] = np.where(\n",
    "    area_code_summary['population_1950'] >= area_code_summary['population_1950'].median(),\n",
    "    'High Pop',\n",
    "    'Low Pop'\n",
    ")\n",
    "\n",
    "# Fit regression models within each group\n",
    "import statsmodels.api as sm\n",
    "\n",
    "stratified_models = []\n",
    "for group_name, group_data in area_code_summary.groupby('pop_group'):\n",
    "    X = sm.add_constant(group_data['black_prop'])\n",
    "    y = group_data['dial_pulls']\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    # Store results\n",
    "    results = pd.DataFrame({\n",
    "        'group': [group_name],\n",
    "        'term': ['black_prop'],\n",
    "        'estimate': [model.params['black_prop']],\n",
    "        'std.error': [model.bse['black_prop']],\n",
    "        'statistic': [model.tvalues['black_prop']],\n",
    "        'p.value': [model.pvalues['black_prop']]\n",
    "    })\n",
    "    \n",
    "    stratified_models.append(results)\n",
    "\n",
    "stratified_models = pd.concat(stratified_models)\n",
    "stratified_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61af3b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot regression results\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "for group_name, group_data in area_code_summary.groupby('pop_group'):\n",
    "    plt.scatter(\n",
    "        group_data['black_prop'],\n",
    "        group_data['dial_pulls'],\n",
    "        label=group_name,\n",
    "        alpha=0.6,\n",
    "        s=70\n",
    "    )\n",
    "    \n",
    "    # Add regression line\n",
    "    x = group_data['black_prop']\n",
    "    y = group_data['dial_pulls']\n",
    "    z = np.polyfit(x, y, 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_range = np.linspace(x.min(), x.max(), 100)\n",
    "    plt.plot(x_range, p(x_range), '--')\n",
    "\n",
    "plt.title('Stratified Regression by Population Group', fontsize=14)\n",
    "plt.xlabel('Proportion Black (1950)')\n",
    "plt.ylabel('Dial Pulls')\n",
    "plt.legend(title='Population Group')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de51d1ca",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# COMPONENT 5: Predicting Area Code Growth\n",
    "\n",
    "### Note on Evaluation Metric: Poisson Log Loss\n",
    "\n",
    "In this component, we aimed to predict how many descendant area codes each original code would eventually generate—a measure of telecommunication demand and population pressure.\n",
    "\n",
    "Although our primary evaluation metrics were RMSE and R², it's important to recognize that `n_descendants` is a count response variable. For count data, the **Poisson log loss** (also known as **Poisson deviance**) is a more appropriate loss function. It better reflects the likelihood-based fit for count outcomes.\n",
    "\n",
    "The number of descendant area codes for each original code reflects long-term telecommunication demand. Using 1950-era features (e.g. population, phone usage, demographics), we seek to predict this count using multiple statistical and machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bebe8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Poisson log loss function\n",
    "def poisson_log_loss(y_true, y_pred):\n",
    "    return np.sum(y_pred - y_true * np.log(y_pred + 1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ac9df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset for modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Prepare the dataset\n",
    "area_data = area_code_summary.drop(columns=['original_code']).copy()\n",
    "area_data['middle_code'] = area_data['middle_code'].astype('category')\n",
    "area_data = area_data.dropna()\n",
    "\n",
    "# Split data\n",
    "np.random.seed(123)\n",
    "train_idx, test_idx = train_test_split(area_data.index, test_size=0.2)\n",
    "area_train = area_data.loc[train_idx]\n",
    "area_test = area_data.loc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927512b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "feature_cols = [col for col in area_train.columns if col not in ['n_descendants', 'state']]\n",
    "X_train = area_train[feature_cols]\n",
    "y_train = area_train['n_descendants']\n",
    "X_test = area_test[feature_cols]\n",
    "y_test = area_test['n_descendants']\n",
    "\n",
    "# Handle categorical variables\n",
    "X_train = pd.get_dummies(X_train, columns=['middle_code', 'type', 'pop_group'], drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns=['middle_code', 'type', 'pop_group'], drop_first=True)\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Standardize numeric features\n",
    "numeric_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "scaler = StandardScaler()\n",
    "X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc92cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression baseline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lm_model = LinearRegression()\n",
    "lm_model.fit(X_train, y_train)\n",
    "lm_preds = lm_model.predict(X_test)\n",
    "\n",
    "lm_rmse = np.sqrt(mean_squared_error(y_test, lm_preds))\n",
    "lm_r2 = r2_score(y_test, lm_preds)\n",
    "\n",
    "print(f\"Linear Regression - RMSE: {lm_rmse:.3f}, R²: {lm_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3e450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define alternative models\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "\n",
    "models = {\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    'Lasso': Lasso(alpha=1.0),\n",
    "    'KNN': KNeighborsRegressor(n_neighbors=5),\n",
    "    'Tree': DecisionTreeRegressor(),\n",
    "    'Boosted': XGBRegressor(),\n",
    "    'Poisson': PoissonRegressor()\n",
    "}\n",
    "\n",
    "# Fit models and evaluate\n",
    "model_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    \n",
    "    model_results.append({\n",
    "        'model': name,\n",
    "        'rmse': rmse,\n",
    "        'rsq': r2\n",
    "    })\n",
    "\n",
    "# Add linear model results\n",
    "model_results.append({\n",
    "    'model': 'Linear',\n",
    "    'rmse': lm_rmse,\n",
    "    'rsq': lm_r2\n",
    "})\n",
    "\n",
    "# Compare all models\n",
    "results_df = pd.DataFrame(model_results).sort_values('rmse')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0451b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stepwise regression\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Convert dataframe to format for statsmodels\n",
    "train_data_sm = area_train.drop(columns=['state'])\n",
    "test_data_sm = area_test.drop(columns=['state'])\n",
    "\n",
    "# Convert categorical variables\n",
    "train_data_sm = pd.get_dummies(train_data_sm, columns=['middle_code', 'type', 'pop_group'], drop_first=True)\n",
    "test_data_sm = pd.get_dummies(test_data_sm, columns=['middle_code', 'type', 'pop_group'], drop_first=True)\n",
    "test_data_sm = test_data_sm.reindex(columns=train_data_sm.columns, fill_value=0)\n",
    "\n",
    "# Full model\n",
    "X_sm = sm.add_constant(train_data_sm.drop(columns=['n_descendants']))\n",
    "y_sm = train_data_sm['n_descendants']\n",
    "full_model = sm.OLS(y_sm, X_sm).fit()\n",
    "\n",
    "# Forward stepwise selection (simplified implementation)\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "step_selector = SequentialFeatureSelector(\n",
    "    LinearRegression(),\n",
    "    n_features_to_select=6,  # Simplified - normally would use a criterion\n",
    "    direction='forward'\n",
    ")\n",
    "\n",
    "step_selector.fit(X_train, y_train)\n",
    "selected_features = X_train.columns[step_selector.get_support()].tolist()\n",
    "\n",
    "# Fit model with selected features\n",
    "X_train_step = X_train[selected_features]\n",
    "X_test_step = X_test[selected_features]\n",
    "\n",
    "step_model = LinearRegression().fit(X_train_step, y_train)\n",
    "step_preds = step_model.predict(X_test_step)\n",
    "\n",
    "step_rmse = np.sqrt(mean_squared_error(y_test, step_preds))\n",
    "step_r2 = r2_score(y_test, step_preds)\n",
    "\n",
    "print(f\"Stepwise Model - RMSE: {step_rmse:.3f}, R²: {step_r2:.3f}\")\n",
    "print(f\"Selected features: {selected_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243104f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted vs actual\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(y_test, lm_preds, label='Full Linear Model', alpha=0.7, s=70)\n",
    "plt.scatter(y_test, step_preds, label='Stepwise Model', alpha=0.7, s=70)\n",
    "plt.plot([0, y_test.max()], [0, y_test.max()], 'k--')\n",
    "\n",
    "plt.title('Predicted vs Actual for Full vs Stepwise Models', fontsize=14)\n",
    "plt.xlabel('Actual Descendant Count')\n",
    "plt.ylabel('Predicted')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfcd119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable importance from boosted model\n",
    "boost_model = XGBRegressor()\n",
    "boost_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance\n",
    "importance = boost_model.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': importance\n",
    "}).sort_values('Importance', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.title('Feature Importance from Boosted Tree Model', fontsize=14)\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225d1f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to binary classification (high vs low growth)\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "\n",
    "# Define high growth as 2+ descendants\n",
    "y_test_binary = (y_test >= 2).astype(int)\n",
    "step_preds_binary = (step_preds >= 2).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "conf_mat = confusion_matrix(y_test_binary, step_preds_binary)\n",
    "accuracy = accuracy_score(y_test_binary, step_preds_binary)\n",
    "sensitivity = recall_score(y_test_binary, step_preds_binary)\n",
    "specificity = recall_score(1 - y_test_binary, 1 - step_preds_binary)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)\n",
    "print(f\"\\nAccuracy: {accuracy:.3f}\")\n",
    "print(f\"Sensitivity: {sensitivity:.3f}\")\n",
    "print(f\"Specificity: {specificity:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19265a8f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "- **Population matters**: More populated areas received easier codes, especially in states with multiple code options.\n",
    "- **Racial disparities exist**: Black-majority areas in urban states were assigned more difficult-to-dial codes.\n",
    "- **Births predict growth**: Early birth rates are strongly predictive of long-term telecom demand.\n",
    "- **Simple models work**: Despite testing complex algorithms, a stepwise linear model outperformed them all.\n",
    "\n",
    "## Summary\n",
    "\n",
    "This project used spatial joins, demographic aggregation, correlation analysis, and predictive modeling to reverse-engineer the logic behind the 1947 area code map. Along the way, we uncovered compelling evidence of bias both in favor of high-population areas and against predominantly Black communities. Perhaps more importantly, we showed that early indicators like births and phone ownership were not only used to justify code assignments but could successfully forecast how those codes would evolve.\n",
    "\n",
    "While the dataset reflects a specific moment in U.S. infrastructure history, the lessons extend far beyond telecom. It reminds us that design decisions—even numeric ones—can have long-lasting social consequences. And with the right tools, we can make those patterns visible."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
